{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Images for OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covered in this Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inverted Images\n",
    "2. Rescaling\n",
    "3. Binarization\n",
    "4. Noise Removal\n",
    "5. Dilation and Erosion\n",
    "6. Rotation / Deskewing\n",
    "7. Removing Borders\n",
    "8. Missing Borders\n",
    "9. Transparency / Alpha Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00: Opening an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "image_file = \"data/page_01.jpg\"\n",
    "img = cv2.imread(image_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/28816046/\n",
    "#displaying-different-images-with-actual-size-in-matplotlib-subplot\n",
    "def display(im_path):\n",
    "    dpi = 80\n",
    "    im_data = plt.imread(im_path)\n",
    "\n",
    "    height, width  = im_data.shape[:2]\n",
    "    \n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the image.\n",
    "    ax.imshow(im_data, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01: Inverted Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_image = cv2.bitwise_not(img)\n",
    "cv2.imwrite(\"temp/inverted.jpg\", inverted_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"temp/inverted.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02: Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03: Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_image = grayscale(img)\n",
    "cv2.imwrite(\"temp/gray.jpg\", gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"temp/gray.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh, im_bw = cv2.threshold(gray_image, 210, 230, cv2.THRESH_BINARY)\n",
    "cv2.imwrite(\"temp/bw_image.jpg\", im_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"temp/bw_image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04: Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_removal(image):\n",
    "    import numpy as np\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    image = cv2.dilate(image, kernel, iterations=1)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    image = cv2.erode(image, kernel, iterations=1)\n",
    "    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    image = cv2.medianBlur(image, 3)\n",
    "    return (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_noise = noise_removal(im_bw)\n",
    "cv2.imwrite(\"temp/no_noise.jpg\", no_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"temp/no_noise.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilation and Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thin_font(image):\n",
    "    import numpy as np\n",
    "    image = cv2.bitwise_not(image)\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    image = cv2.erode(image, kernel, iterations=1)\n",
    "    image = cv2.bitwise_not(image)\n",
    "    return (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eroded_image = thin_font(no_noise)\n",
    "cv2.imwrite(\"temp/eroded_image.jpg\", eroded_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"temp/eroded_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thick_font(image):\n",
    "    import numpy as np\n",
    "    image = cv2.bitwise_not(image)\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    image = cv2.dilate(image, kernel, iterations=1)\n",
    "    image = cv2.bitwise_not(image)\n",
    "    return (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilated_image = thick_font(no_noise)\n",
    "cv2.imwrite(\"temp/dilated_image.jpg\", dilated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"temp/dilated_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06: Rotation / Deskewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = cv2.imread(\"data/page_01_rotated.JPG\")\n",
    "display(\"data/page_01_rotated.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://becominghuman.ai/how-to-automatically-deskew-straighten-a-text-image-using-opencv-a0c30aed83df\n",
    "import numpy as np\n",
    "\n",
    "def getSkewAngle(cvImage) -> float:\n",
    "    # Prep image, copy, convert to gray scale, blur, and threshold\n",
    "    newImage = cvImage.copy()\n",
    "    gray = cv2.cvtColor(newImage, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # Apply dilate to merge text into meaningful lines/paragraphs.\n",
    "    # Use larger kernel on X axis to merge characters into single line, cancelling out any spaces.\n",
    "    # But use smaller kernel on Y axis to separate between different blocks of text\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))\n",
    "    dilate = cv2.dilate(thresh, kernel, iterations=2)\n",
    "\n",
    "    # Find all contours\n",
    "    contours, hierarchy = cv2.findContours(dilate, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "    for c in contours:\n",
    "        rect = cv2.boundingRect(c)\n",
    "        x,y,w,h = rect\n",
    "        cv2.rectangle(newImage,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "    # Find largest contour and surround in min area box\n",
    "    largestContour = contours[0]\n",
    "    print (len(contours))\n",
    "    minAreaRect = cv2.minAreaRect(largestContour)\n",
    "    cv2.imwrite(\"temp/boxes.jpg\", newImage)\n",
    "    # Determine the angle. Convert it to the value that was originally used to obtain skewed image\n",
    "    angle = minAreaRect[-1]\n",
    "    if angle < -45:\n",
    "        angle = 90 + angle\n",
    "    return -1.0 * angle\n",
    "# Rotate the image around its center\n",
    "def rotateImage(cvImage, angle: float):\n",
    "    newImage = cvImage.copy()\n",
    "    (h, w) = newImage.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    newImage = cv2.warpAffine(newImage, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return newImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deskew image\n",
    "def deskew(cvImage):\n",
    "    angle = getSkewAngle(cvImage)\n",
    "    return rotateImage(cvImage, -1.0 * angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed = deskew(new)\n",
    "cv2.imwrite(\"temp/rotated_fixed.jpg\", fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"temp/rotated_fixed.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07: Removing Borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"temp/no_noise.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_borders(image):\n",
    "    contours, heiarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cntsSorted = sorted(contours, key=lambda x:cv2.contourArea(x))\n",
    "    cnt = cntsSorted[-1]\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    crop = image[y:y+h, x:x+w]\n",
    "    return (crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_borders = remove_borders(no_noise)\n",
    "cv2.imwrite(\"temp/no_borders.jpg\", no_borders)\n",
    "display('temp/no_borders.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08: Missing Borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = [255, 255, 255]\n",
    "top, bottom, left, right = [150]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_border = cv2.copyMakeBorder(no_borders, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "cv2.imwrite(\"temp/image_with_border.jpg\", image_with_border)\n",
    "display(\"temp/image_with_border.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09: Transparency / Alpha Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
